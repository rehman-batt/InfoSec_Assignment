{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uSgUTXvEO-oP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5d9fd5-fa99-4080-fd50-e7db8a6aa89b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/sid321axn/malicious-urls-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16.9M/16.9M [00:00<00:00, 42.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded at: /root/.cache/kagglehub/datasets/sid321axn/malicious-urls-dataset/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m16280/16280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1303s\u001b[0m 80ms/step - accuracy: 0.9222 - loss: 0.2115 - val_accuracy: 0.9568 - val_loss: 0.1164\n",
            "Epoch 2/5\n",
            "\u001b[1m16280/16280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1187s\u001b[0m 73ms/step - accuracy: 0.9593 - loss: 0.1085 - val_accuracy: 0.9599 - val_loss: 0.1072\n",
            "Epoch 3/5\n",
            "\u001b[1m16280/16280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1231s\u001b[0m 73ms/step - accuracy: 0.9632 - loss: 0.0963 - val_accuracy: 0.9614 - val_loss: 0.1025\n",
            "Epoch 4/5\n",
            "\u001b[1m16280/16280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1286s\u001b[0m 79ms/step - accuracy: 0.9651 - loss: 0.0907 - val_accuracy: 0.9621 - val_loss: 0.1010\n",
            "Epoch 5/5\n",
            "\u001b[1m16280/16280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1257s\u001b[0m 77ms/step - accuracy: 0.9662 - loss: 0.0873 - val_accuracy: 0.9622 - val_loss: 0.1028\n",
            "Epoch 1/5\n",
            "\u001b[1m16280/16280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 32ms/step - accuracy: 0.9332 - loss: 0.1817 - val_accuracy: 0.9582 - val_loss: 0.1130\n",
            "Epoch 2/5\n",
            "\u001b[1m16280/16280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 31ms/step - accuracy: 0.9619 - loss: 0.1007 - val_accuracy: 0.9612 - val_loss: 0.1060\n",
            "Epoch 3/5\n",
            "\u001b[1m16280/16280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 31ms/step - accuracy: 0.9645 - loss: 0.0919 - val_accuracy: 0.9599 - val_loss: 0.1081\n",
            "Epoch 4/5\n",
            "\u001b[1m16280/16280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 30ms/step - accuracy: 0.9673 - loss: 0.0847 - val_accuracy: 0.9610 - val_loss: 0.1060\n",
            "Epoch 5/5\n",
            "\u001b[1m16280/16280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 29ms/step - accuracy: 0.9684 - loss: 0.0814 - val_accuracy: 0.9610 - val_loss: 0.1113\n",
            "\n",
            "LSTM Evaluation:\n",
            "\u001b[1m4070/4070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 18ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.96      0.99      0.97     85778\n",
            "  defacement       0.99      0.99      0.99     19104\n",
            "     malware       0.99      0.96      0.97      6521\n",
            "    phishing       0.93      0.81      0.87     18836\n",
            "\n",
            "    accuracy                           0.96    130239\n",
            "   macro avg       0.97      0.94      0.95    130239\n",
            "weighted avg       0.96      0.96      0.96    130239\n",
            "\n",
            "\n",
            "CNN Evaluation:\n",
            "\u001b[1m4070/4070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.96      0.98      0.97     85778\n",
            "  defacement       0.99      0.99      0.99     19104\n",
            "     malware       0.99      0.96      0.97      6521\n",
            "    phishing       0.90      0.83      0.86     18836\n",
            "\n",
            "    accuracy                           0.96    130239\n",
            "   macro avg       0.96      0.94      0.95    130239\n",
            "weighted avg       0.96      0.96      0.96    130239\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Download dataset using kagglehub\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"sid321axn/malicious-urls-dataset\")\n",
        "print(\"Dataset downloaded at:\", path)\n",
        "\n",
        "# Step 2: Load and preprocess data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, GlobalMaxPooling1D\n",
        "\n",
        "df = pd.read_csv(f\"{path}/malicious_phish.csv\")\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "X = df['url']\n",
        "y = df['type']\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_seq = tokenizer.texts_to_sequences(X)\n",
        "X_pad = pad_sequences(X_seq, maxlen=100)\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Build and train LSTM model\n",
        "model_lstm = Sequential([\n",
        "    Embedding(5000, 64, input_length=100),\n",
        "    LSTM(64),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(len(np.unique(y_encoded)), activation='softmax')\n",
        "])\n",
        "model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_lstm.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 4: Build and train CNN model\n",
        "model_cnn = Sequential([\n",
        "    Embedding(5000, 64, input_length=100),\n",
        "    Conv1D(128, 5, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(len(np.unique(y_encoded)), activation='softmax')\n",
        "])\n",
        "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 5: Evaluation\n",
        "print(\"\\nLSTM Evaluation:\")\n",
        "y_pred_lstm = model_lstm.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, y_pred_lstm, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nCNN Evaluation:\")\n",
        "y_pred_cnn = model_cnn.predict(X_test).argmax(axis=1)\n",
        "print(classification_report(y_test, y_pred_cnn, target_names=le.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1D8wnk7CbszP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}